{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Min and Top K heavy Hitters based leaderboard for Game of Thrones Characters\n",
    "\n",
    "We obtain the elasticsearch index connected at localhost:9200 and stream 1000 lastest tweets that have used common Game of Thrones tags mentioned in the other iPython Notebook and reproduced here:\n",
    "'#got', '#gameofthrones', '#winteriscoming', '#winterishere', '#winterfell', '#gotseason', '#asongoficeandfire'\n",
    "\n",
    "The tweets that are streamed using these hahstags are indexed in Elasticsearch. We have implemented five DRPC queries, namely:\n",
    "    1. Match Query\n",
    "    2. Match Query with AND operation\n",
    "    3. Aggregation Query\n",
    "    4. Term Query\n",
    "    5. Range Query\n",
    "\n",
    "These will be explained as we run you through this application of Count Min Sketches and Bloom Filters to generate a leaderboard for Game of Thrones Characters. \n",
    "The implementation of Bloom Filters and Count Min Sketches is in two other python files named `BloomFilter.py` and `MinSketch.py`. Their implementation has been explained within these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from BloomFilter import *\n",
    "from MinCount import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we import all requires libraries and modules we need to first connect with elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_conn = Elasticsearch('localhost:9200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now go through the DRPC query implemented here.\n",
    "#### Match Query\n",
    "    This query matches the exact same keyword that has been input into the function and delivers 1000 ES queries ordered in a descending manner of their creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_query(keyword):\n",
    "    query={\n",
    "        \"query\":{\n",
    "            \"match\":{\n",
    "                \"text\":keyword\n",
    "            }\n",
    "        },\n",
    "        \"sort\": [\n",
    "        {\n",
    "          \"timestamp\": {\n",
    "            \"order\": \"desc\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "    response = es_conn.search(index= 'stock', body = query, size=1000)\n",
    "    return response\n",
    "    if response.get('hits', {}).get('total', 0) > 0:\n",
    "        return response['hits']['hits'][0]['_source']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of Bloom Filter and Count Min Sketches in generating a leaderboard for Game of Thrones characters\n",
    "\n",
    "Here we have 31 popular characters of Game of Thrones using whose names we have generated a Bloom Filter. Considering an error rate of 1%, we calculated the size of the Bloom Filter and the Count Min Sketch as such:  \n",
    "\n",
    "    n = 31  \n",
    "    p = 0.01  \n",
    "    m = 300 (approximated from 297.13 ~ 298)  \n",
    "    k = 7  \n",
    "    Hence we have a min sketch & bloom filter of length 300 and it uses 7 hash functions.  \n",
    "\n",
    "The manner of execution of this leaderboard involves first preprocessing the input twitter text to remove punctuation and converting it to lower case, after which it must be tokenised. The Bloom Filter is created and cross checked to determine if the current word is contained in the bloom filter. In case it is, its Count Min Sketch is updated to reflect this. The leaderboard is a dictionary that is updated with every new instance of a word referenced in the boom filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n",
      "[(27, 'samwell'), (41, 'bran'), (60, 'got\\xe2\\x80\\xa6'), (86, 'cersei'), (176, 'jon')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2a3730384ed1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0msorted_leaderboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mleaderboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0msorted_leaderboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:    \n",
    "    bloom = BloomFilter(31, 300, 7)\n",
    "    bloom.createBloom()\n",
    "    CMS = MinCount(300, 7)\n",
    "    names = [\"ned\", \"eddard\", \"robert\", \"jamie\", \"catelyn\", \"cersei\", \"daenerys\", \"jorah\", \"viserys\", \"jon\", \"sansa\", \"arya\", \"theon\", \"bran\", \"joffrey\", \"tyrion\", \"baelish\", \"davos\", \"samwell\", \"stannis\", \"melisandre\", \"jeor\", \"bronn\", \"varys\", \"tywin\", \"gendry\", \"brienne\", \"ramsay\", \"gilly\", \"daario\", \"missandei\"]\n",
    "\n",
    "    leaderboard = {i: 0 for i in names}\n",
    "\n",
    "    query_res = match_query(\"got\")['hits']['hits']\n",
    "    \n",
    "    final = []\n",
    "    for value in query_res:\n",
    "        text = str(value['_source']['text'].encode('utf-8')).lower().translate(None, string.punctuation)\n",
    "        word_tokens = word_tokenize(text)\n",
    "\n",
    "        for word in word_tokens:\n",
    "            if bloom.checkBloom(word):\n",
    "                CMS.insertCMS(word)\n",
    "                c = CMS.count(word)\n",
    "                leaderboard[word] = c\n",
    "                filtered_words.append(word)\n",
    "\n",
    "    sorted_leaderboard = sorted((value, key) for (key,value) in leaderboard.items())\n",
    "    print sorted_leaderboard[-5:]\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
